\section{Preliminaries}
\subsection{Fields}
\begin{definition}
	A \defn{field} is a set $F$ with a pair of binary operations $+$ and $\times$, called \emph{addition} and \emph{multiplication}, such that
	\begin{enumerate}
		\item $F$ is an abelian group with respect to $+$. That is, $+$ is associative and commutative, there exists a neutral element $0$ such that $a + 0 = a$ for all $a \in F$, and for all $a \in F$ there exists an element $(-a) \in F$ such that $a + (-a) = 0$;
		\item The multiplication on $F$ is associative and commutative, there exists a multiplicative identity element $1 \neq 0$ such that $1 \cdot a = a$ for all $a \in F$, and for all $a \in F$, $a \neq 0$, there exists an element $a^{-1} \in F$ such that $a \cdot a^{-1}$;
		\item For all $a, b, c \in F$, $a(b + c) = ab + ac$ (distributivity).
	\end{enumerate}
\end{definition}

\begin{example}
	$\Q$, $\R$, $\C$ and $\Z_p = \Z / p\Z$, where $p$ is a prime, are all fields.
\end{example}

\begin{remarks} \hfill
	\begin{itemize}
		\item $0$ and $1$ are unique, and for all $a \in F$, $-a$ is unique. If $a \neq 0$ then $a^{-1}$ is unique.
		\item The condition $1 \neq 0$ is equivalent to the condition that $F$ has at least two elements.
	\end{itemize}
\end{remarks}

\begin{definition}
	Suppose $F$ is a field and $E \subset F$. If $E$ is a field with respect to the binary operations of $F$, then we say that $E$ is a \defn{subfield}.
	
	In fact, a subset $E$ of a field $F$ is a subfield if and only if
	\begin{itemize}
		\item $0, 1 \in E$;
		\item $E$ is closed under $+$ and $\times$; and
		\item $E$ is closed under taking additive and multiplicative inverses.
	\end{itemize}
\end{definition}

\begin{definition}
	The \defn{characteristic} of a field $F$ is the  smallest $n \in \N$ such that $n \cdot 1 = \underbrace{1 + \ldots + 1}_{n \text{ times}} = 0$.
	
	If there is no such $n$, we say that $F$ has characteristic $0$.
\end{definition}

\begin{proposition}
	If $F$ has positive characteristic, then the characteristic is a prime number.
	\begin{proof}
		Suppose we have $n \cdot 1 = 0$ with $n = m \cdot k$ for some $m, k \in \N$. Then
		\[
			n \cdot 1 = \underbrace{1 + \ldots + 1}_{n \text{ times}} = (\underbrace{1 + \ldots + 1}_{m \text{ times}})(\underbrace{1 + \ldots + 1}_{k \text{ times}}) = (m \cdot 1)(k \cdot 1) = 0.
		\]
		Now if the product of 2 elements is $0$ in a field, then at least one of these elements must be zero (since a field has no zero divisors). So if we take the prime factorisation of $n$, the result follows.
	\end{proof}
\end{proposition}

\begin{remarks}\hfill
	\begin{itemize}
		\item If a field $F$ has characteristic $p$, $p$ a prime, then $p \cdot a = 0$ for all $a \in F$:
		\[
			p \cdot a = \underbrace{a + \ldots + a}_{p \text{ times}} = a(\underbrace{1 + \ldots + 1}_{p \text{ times}}) = a \cdot 0 = 0.
		\]
		\item $\Q$, $\R$ and $\C$ have characteristic $0$.
		\item $\Z_p$ has characteristic $p$.
	\end{itemize}
\end{remarks}

\begin{definition}
	The smallest subfield of a field $F$ is called the \defn{prime subfield}.
\end{definition}

\begin{proposition}
	The prime subfield of any field is isomorphic to either $\Q$ or $\Z_p$ for some prime $p$.
	\begin{proof}
		A subfield contains $0$ and $1$, hence it contains all elements $n \cdot 1 = \underbrace{1 + \ldots + 1}_{n \text{ times}}$. It is easy to see the map $\varphi : \Z \to F$ defined by $n \mapsto n \cdot 1$ extends to a (ring) homomorphism (see the First Isomorphism Theorem for rings).
		
		If $\chr{F} = 0$, then $\ker{\varphi} = \{0\}$. Therefore $F$ contains an isomorphic copy of $\Z$, but then it also contains an isomorphic copy of $\Q$ (since $\Q$ contains all the multiplicative inverses of $\Z$). Again, see the First Isomorphism Theorem for rings.
		
		If $\chr{F} = p$ then $\ker{\varphi} = p\Z$. Therefore $F$ contains an isomorphic copy of $\Z_p = \Z / p\Z$, which is  a field. So this must be the prime subfield.
	\end{proof}
\end{proposition}

\begin{notation}
	In field theory, if $a \neq 0$, we often write $a^{-1} = \frac{1}{a}$ and $\frac{b}{a} = a^{-1}b$.
\end{notation}

\subsection{Homogeneous Linear Systems}
Suppose we have a field $F$. Then the equation $ax = b$, $a, b \in F$, $a \neq 0$, has a unique solution in F. This is given by $x = a^{-1}b$. This is one of the most important features of a field $F$.

In particular, $x = 0$ is the only solution of $ax = 0$, ($a \neq 0$).

More generally, the system
\begin{equation} \label{eq:hom-system}
	\left.
	\begin{matrix}
		a_{11} x_1 &+& a_{12} x_2 &+& \ldots &+& a_{1n} x_n &=& 0 \\
		\vdots	   & & \vdots	  & & \vdots & & \vdots		& & \vdots \\
		a_{m1} x_1 &+& a_{m2} x_2 &+& \ldots &+& a_{mn} x_n &=& 0
	\end{matrix}
	\right\}
\end{equation}
($a_{ij} \in F$) always has the \emph{trivial} solution $x_1 = x_2 = \ldots = x_n = 0$. Any other solution is called \emph{non-trivial}.

\begin{theorem} \label{thm:1}
	A homogeneous system (\ref{eq:hom-system}) has a non-trivial solution if $n > m$. (i.e. The number of variables is greater than the number of equations.)
	\begin{proof}
		If $m = 1$ and $a_1 \neq 0$, we may set $x_2 = \ldots = x_n = 1$ and $x_1 = -a_1^{-1}(a_2 \cdot 1 + \ldots + a_n \cdot 1)$.
		
		If $a_1$ = 0, we may set $x_1 = 1$ and $x_2 = \ldots = x_n = 0$.
		
		We proceed by induction on $m$.
		
		Let $n > m > 1$ in (\ref{eq:hom-system}). Define $L_i$ by
		\[
			L_i = a_{i 1} x_1 + a_{i 2} x_2 + \ldots + a_{i n} x_n = 0.
		\]
		We want to find elements $x_1, \ldots, x_n \in F$ (which are not all zero) such that $L_1 = L_2 = \ldots = L_m = 0$.
		
		Now if $a_{i j} = 0$ for all $i, j$, then any choice of $x_1, \ldots, x_n$ is a solution.
		
		If not all $a_{i j} = 0$, we may without loss of generality assume $a_{1 1} \neq 0$ (by renumbering the unknowns and / or equations if necessary). Notice that we can find a non-trivial solution of the system (\ref{eq:hom-system}) with $a_{1 1} \neq 0$ if and only if there is a non-trivial solution of the system
		\begin{equation} \label{eq:hom-system2}
			\left.
			\begin{matrix}
				L_1							 &=& 0 \\
				L_2 - a_{21} a_{11}^{-1} L_1 &=& 0 \\
				\vdots						 & & \vdots \\
				L_m - a_{m1} a_{11}^{-1} L_1 &=& 0.
			\end{matrix}
			\right\}
		\end{equation}
		Notice that system (\ref{eq:hom-system2}) consists of the equation $L_1 = 0$ and another system of $m - 1$ equations in $n$ variables, which we will denote (\ref{eq:hom-system2}$'$). Notice the coefficients at $x_1$ are zero in (\ref{eq:hom-system2}$'$), and so we may view these (\ref{eq:hom-system2}$'$) as a system of $m - 1$ equations in $n - 1$ variables $x_2, \ldots, x_n$. So by the induction hypothesis, (\ref{eq:hom-system2}$'$) has a non-trivial solution, say $x_2, \ldots, x_n$. So this solution together with $x_1 = a_{11}^{-1}(a_{12}x_2 + \ldots + a_{1n}x_n)$ is a solution of (\ref{eq:hom-system2}) and thus (\ref{eq:hom-system}).
	\end{proof}
\end{theorem}

\begin{remark}
	The key element in the proof is Gaussian elimination, namely the elimination of $x_1$.
\end{remark}

\subsection{Vector Spaces}
\begin{definition}
	A \defn{vector space} over a field $F$ is an additively written abelian group $V$ with a scalar multiplication $F \times V \to V$ such that
	\begin{enumerate}
		\item $a(A + B) = aA + aB$ \qquad for all $a \in F$ and for all $A, B \in V$;
		\item $(a + b)A = aA + bA$ \qquad for all $a, b \in F$ and for all $A \in V$;
		\item $a(bA) = (ab)A$ \qquad for all $a, b \in F$ and for all $A \in V$;
		\item $1 \cdot A = A$ \qquad for all $A \in V$.
	\end{enumerate}
\end{definition}

\begin{remark}
	We have $0 \cdot A = 0$ for all $A \in V$. Also, if $A \neq 0$ then $aA = 0$ if and only if $a = 0$.
	
	Note that all these zeros are not the same, since 0 may be the zero vector. It should be clear from the context what `0' actually refers to.
\end{remark}

\begin{examples}\hfill
	\begin{itemize}
		\item (Most important.) If $F$ is a subfield of $E$, then $E$ is a vector space over $F$ with scalar multiplication given by the multiplication in $E$.
		\item (The mother of all vector spaces.) $F^n = F \times \ldots \times F$, the space of row (or column) vectors with entries in $F$.
	\end{itemize}
\end{examples}

\subsection{Dependence and Independence of Vectors, Bases and Dimension}
\begin{definition}
	In a vector space $V$ over a field $F$, the vectors $A_1, \ldots, A_n$ are called \emph{linearly dependent}\index{linearly!dependent} if there exist elements $x_1, \ldots, x_n \in F$ (which are not all zero) such that
	\[
		x_1 A_1 + x_2 A_2 + \ldots + x_n A_n = 0.
	\]
	The vectors $A_1, \ldots, A_n$ are \emph{linearly independent}\index{linearly!independent} if they are not linearly dependent.
	
	An \emph{infinite system} of vectors is linearly independent if every finite subsystem is linearly independent.
\end{definition}

\begin{definition}
	Let $I$ be some index set. A system $\mathcal{A} = \{A_i\}_{i \in I}$ of vectors in $V$ is a \defn{generating set} (or \defn{spanning set}) if each element of $V$ can be expressed as a linear combination of vectors from $\mathcal{A}$.
	
	A vector space is called \emph{finite dimensional}\index{finite!dimensional vector space} if it has a finite generating set.
\end{definition}

\begin{definition}
	A linearly independent generating set in a vector space is called a \defn{basis} (or \defn{baaay-sis}).
\end{definition}

\begin{theorem}[Main Theorem of Linear Algebra]\index{Main Theorem of Linear Algebra}
	Any finite dimensional vector space $V$ over some field $F$ has a finite basis. Any two bases of $V$ have the same number of elements. This number is called the dimension of $V$, denoted by $\dim{V}$ or $\dim_F{V}$.
\end{theorem}

Moreover, in a finite dimensional vector space $V$ with $\dim{V} = n$,
\begin{itemize}
	\item Any generating set contains a basis;
	\item Any set of linearly independent vectors can be extended to a basis;
	\item Any set of $n$ linearly independent vectors is a basis;
	\item Any generating set consisting of $n$ vectors is a basis.
\end{itemize}

\begin{example}
	The space of column vectors $F^n$ is a vector space of dimension $n$. So we can have a set $\{e_1, \ldots, e_n\}$ with
	\[
		e_i =
		\begin{pmatrix}
			0 \\
			\vdots \\
			1 \\
			\vdots \\
			0
		\end{pmatrix}
		% Should find a way to do the following nicely.
		\begin{matrix}
			 \\
			 \\
			\leftarrow i\text{-th row} \\
			 \\
			 \\
		\end{matrix}
	\]
	which is a basis -- the \defn{standard basis}.
\end{example}
